{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome","text":"<p>Note</p> <p>This guide and collection of resources was created as part of a workshop at the Openmod 2025 in Stockholm and to create a database for classic questions in general.</p> <p>Software development can be hard and most people struggle with similar problems. But there are many low hanging fruits with tools and processes that make it easy to build your own open source software. </p> <p>This document will give you a brief introduction to the different steps you can take to get your project up running and sustain a healthy open source project.</p>"},{"location":"#topics","title":"Topics","text":"<ol> <li>Write - Get started with writing your code</li> <li>Build - Create a python package</li> <li>Test - Add testing strategies to your project</li> <li>Format - Use code formatters to make your code look nice</li> <li>Type - Use type hints to make your code more readable and maintainable</li> <li>Document - Publish documentation and a API reference</li> <li>Release - Choose a release strategy</li> <li>CI - Use continuous integration to automate your workflow</li> <li>Publish - Get your package out to the world</li> <li>Maintain - Keep your project alive</li> </ol> <p>Info</p> <p>It is not a complete guide but rather a collection of resources and links to help you get started. The goal is to provide you with a starting point and some best practices that you can follow to make your project more successful.</p> <p>Contributing</p> <p>Any contribution is welcome!</p> <ul> <li>The guide only provides a couple of tools and topics. If you have a tool or topic that you think is missing, please add it to the list.</li> <li>Any typos or mistakes in the text? Please open an issue or a pull request. You can get to the source code of this page by clicking on the pencil icon in the top right corner.</li> </ul>"},{"location":"#guide-for-the-workshop","title":"Guide for the Workshop","text":"<p>The document only provides information. During the workshop there are multiple things you can do:</p> <ul> <li> <p>Demo project</p> <p>Each section links to a demo project that shows how you could implement the topic. You can create your own project and use the demo project as an example. Or just jump into the topic you are interested in. Maybe you want to publish the project on the PyPi test server or play around with different testing strategies.</p> </li> <li> <p>Improve your own project</p> <p>If you have a project that you want to improve, you can jump in at any topic and work on your own project. Maybe it's time to add a formatter to your project and discover some linting rules. Or you start to add some tests which you always wanted to do. Maybe you have a running PyPi package already, but you want to make it available via conda as well.</p> </li> <li> <p>Share your own experience</p> <p>If you already know most of the common steps involved in package development, you can share your own experiences. Maybe this guide misses a topic you think is important, or you think GitLab is a better alternative to GitHub.</p> </li> </ul>"},{"location":"steps/build/","title":"2. Build","text":"<p>Now that you have written your code, it is time to build a package. This is the first step in making your code available to the world. It is basically the process of going from a directory containing your code to a package that can be installed using a package manager such as <code>pip</code>, <code>conda</code> or <code>uv</code>.</p> <p>Example</p> <p>See demo project:</p> <p> Before |  After |  Diff</p>"},{"location":"steps/build/#packaging","title":"Packaging","text":"<p>To package your code, you need to choose a build system. The most common ones are <code>setuptools</code> and <code>poetry</code>. Each has its own advantages and disadvantages. For a detailed guide, see the official packaging guide.</p>"},{"location":"steps/build/#project-structure","title":"Project Structure","text":"<p>In short, you want to create a couple of files and restructure your code:</p> <pre><code>python-package-demo/\n\u251c\u2500\u2500 src/\n\u2502   \u2514\u2500\u2500 python_package_demo/\n\u2502       \u251c\u2500\u2500 __init__.py\n\u2502       \u2514\u2500\u2500 example.py\n\u251c\u2500\u2500 LICENSE\n\u251c\u2500\u2500 pyproject.toml\n\u251c\u2500\u2500 README.md\n\u2514\u2500\u2500 ...\n</code></pre> <ul> <li><code>LICENSE</code>: The license file for your project. This is important to let people know how they can use your code.</li> <li><code>pyproject.toml</code>: The configuration file for your package. This is where you define the build system and other metadata for your package. It can also be used to configurate other tools like <code>ruff</code>, <code>uv</code>, <code>mypy</code> and <code>black</code>.</li> <li><code>README.md</code>: The readme file for your project. This is where you provide information about your project and how to use it.</li> <li><code>src/</code>: The source code of your project.</li> </ul> <p>Info</p> <p>The <code>src/</code> directory is not required as a parent directory, but it is recommended to use it. It helps to avoid naming conflicts with other packages, and makes it easier to manage your code. For more details, see src layout vs flat layout.</p> <p>Info</p> <p>While <code>setup.py</code> is still supported and not deprecated, using a single <code>pyproject.toml</code> to configure your package is the recommended way to go.</p>"},{"location":"steps/build/#pyprojecttoml-file","title":"<code>pyproject.toml</code> file","text":"<p>As a simple example, we will use <code>setuptools</code> as the build system. The <code>pyproject.toml</code> file is the configuration file for your package. It contains all the metadata and configuration for your package. Here is a simple example:</p> <pre><code>[build-system]\nrequires = [\"setuptools\", \"wheel\"]\nbuild-backend = \"setuptools.build_meta\"\n\n[project]\nname = \"python-package-demo\"\nversion = \"0.1.0\"\ndescription = \"A demo project for packaging python code\"\nreadme = \"README.md\"\nlicense = { file = \"LICENSE\" }\nauthors = [{name = \"Your Name\", email = \"your-email@mail.org\"}]\nrequires-python = \"&gt;=3.8\"\ndependencies = [\n    \"numpy&gt;=1.21.0\",\n    \"pandas&gt;=1.3.0\",\n]\n</code></pre> <p>This will already be enough to install your package via <code>pip</code>:</p> <pre><code>pip install .\n# or \npip install -e . # for editable mode\n</code></pre> <p>You can also use <code>pip</code> to build your package:</p> <pre><code>pip wheel .\n</code></pre> <p>This is the way how you publish your package to the world. It is discussed in the publish section.</p> <p>Info</p> <p>As you can see, we hardcode the current version into the <code>pyproject.toml</code> file. This means you have to bump the version on each release. <code>setuptools_scm</code> is another build system which can retrieve the version from your git tags. This is how you would manage your releases and trigger a CI pipeline anyway, so you don't have to worry about updating the version in your <code>pyproject.toml</code> file.</p>"},{"location":"steps/build/#more-metadata","title":"More metadata","text":"<p>You can add more metadata to your package. See Writing your pyproject.toml for more information. Here we add some classifiers and keywords to the package. They are picked up by PyPI, for a full list of available classifiers see PyPI Classifiers.</p> <pre><code>[project]\n# ...\nclassifiers = [\n    # Specify the Python versions you support here\n    \"Programming Language :: Python :: 3\",\n    \"Programming Language :: Python :: 3.8\",\n    \"Programming Language :: Python :: 3.9\",\n    \"Programming Language :: Python :: 3.10\",\n    \"Programming Language :: Python :: 3.11\",\n    \"Programming Language :: Python :: 3.12\",\n    \"Programming Language :: Python :: 3 :: Only\",\n    # License\n    \"License :: OSI Approved :: MIT License\",\n    # Operating System\n    \"Operating System :: OS Independent\",\n]\nkeywords = [\"python\", \"package\", \"demo\"]\n\n[project.urls]\nHomepage = \"https://example.com\"\n</code></pre>"},{"location":"steps/build/#license","title":"License","text":"<p>The licence file is important to let people know how they can use your code. Tools like choosealicense.com/ can help you choose a licence. There is also an OpenMod Guide for choosing a licence.</p>"},{"location":"steps/build/#resources","title":"Resources","text":"<ul> <li>Python Packaging Authority (PyPA)- Python Packaging User Guide</li> <li>Python Packaging Authority (PyPA) - pyproject.toml specification</li> <li>Setuptools documentation</li> <li>The Hitchhiker's Guide to Packaging</li> <li>Packaging Python Libraries - Real Python tutorial</li> <li>Scientific Python Library Development Guide</li> </ul>"},{"location":"steps/ci/","title":"9. CI/CD","text":"<p>Many of the tools and processes discussed here can be used in a CI/CD pipeline. This is a great way to automate your workflow and ensure that your code is always up-to-date, compliant and tested. Without any manual work.</p> <p>Example</p> <p>See demo project:</p> <p> Before |  After |  Diff</p>"},{"location":"steps/ci/#cicd-platforms","title":"CI/CD platforms","text":"<p>There are many CI/CD tools out there. Git hosting platforms have their own CI/CD tools built in. But there are also external tools that can be used.</p> <ul> <li>GitHub Actions</li> <li>GitLab CI/CD</li> <li>Travis CI</li> </ul> <p>You can basically do anything with these services. But in addition there are some external web hooks that can also be triggered by git events, without having to set them up through the platform. Some of these have already been mentioned in the previous sections:</p> <ul> <li>pre-commit.ci</li> <li>ReadTheDocs</li> </ul>"},{"location":"steps/ci/#cicd-jobs","title":"CI/CD jobs","text":"<p>This section will discuss how to set up each job on GitHub Actions, as this is the largest platform for open source projects. But it would work similarly for any other platform. Have a look at the quick start of GitHub Actions. Some tools are also external webhooks and don't rely on a specific platform. But they could also be set up as a separate jobs.</p> <p>Note</p> <pre><code>GitHub Actions refer to the entire CI/CD platform. A GitHub Action is a single action that someone (sometimes GitHub itself) has developed for you to use. Similar to a software package, but for actions.\n</code></pre>"},{"location":"steps/ci/#publish-package","title":"Publish package","text":"<p>Publishing a package most likely means publishing to PyPI. As discussed in the publish section, you can rely on the PyPI trigger to publish to conda forge. You'll also want to publish a small release note to your git hosting platform.</p>"},{"location":"steps/ci/#trigger","title":"Trigger","text":"<p>All publishing steps are usually triggered by a git tag. If you set up <code>setuptools_scm</code> you don't even have to do anything in your project. Just create a tag and push it to your git hosting platform. This will trigger the publish job.</p> <pre><code># Push your commit (if needed)\ngit push upstream main\n# Add a tag to your commit\ngit tag v0.1.0\n# Push the tag to your git hosting platform\ngit push upstream v0.1.0\n</code></pre> <p>and in your GitHub action setup:</p> <pre><code>name: Release\n\non:\n  push:\n    tags:\n    - v*.*.*\n# ...\n</code></pre>"},{"location":"steps/ci/#github-release","title":"GitHub release","text":"<p>To create a GitHub release, you could use a GitHub action like softprops/action-gh-release.</p> <pre><code># ...\n  release:\n    name: Create GitHub release\n    runs-on: ubuntu-latest\n    steps:\n    - uses: actions/checkout@v4\n    - uses: softprops/action-gh-release@v2\n      with:\n        body: |\n          Some custom text: Thanks to all contributors or link to your release notes.\n        append_body: true\n        generate_release_notes: true\n</code></pre> <p>See the [documentation](softprops/action-gh-release of the workflow for all configurations.</p>"},{"location":"steps/ci/#pypi","title":"PyPI","text":"<p>PyPI provides documentation on how to use GitHub actions to publish to PyPI. There is also an action to make it even easier. You should use authentication via a Trusted Publisher.</p>"},{"location":"steps/ci/#tests","title":"Tests","text":"<p>To ensure that all tests pass, you can run them on every commit and pull request in your CI/CD pipeline. A pull request would not be merged if the tests failed. You can also run these tests on a schedule, e.g. every morning, to ensure that any dependencies do not break your code. It's also useful to run your tests on multiple platforms and Python versions if you want to support more than one.</p>"},{"location":"steps/ci/#trigger_1","title":"Trigger","text":"<p>The configuration below will be triggered for every commit to the main branch and every pull request. It will also run on a schedule every day at 5am UTC. If a new commit is pushed before the tests are finished, you can cancel the tests in progress to save time and resources.</p> <pre><code>name: Test\n\non:\n  push:\n    branches:\n    - master\n  pull_request:\n    branches: ['*']\n  schedule:\n  - cron: \"0 5 * * *\"\n\n# Cancel any in-progress runs when a new run is triggered\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.ref }}\n  cancel-in-progress: true\n</code></pre>"},{"location":"steps/ci/#test-matrix","title":"Test matrix","text":"<p>To run multiple tests on different platforms and Python versions, you can use a test matrix. See the documentation for more details. You don't have to support all Python versions, but declare which versions are supported in your <code>pyproject.toml</code>. Python versions get 2 years of support and 5 years of security updates. You should not use an older version. Check the endoflife.date of Python for more details.</p> <pre><code># ...\njobs:\n  test:\n    # Test package build in matrix of OS and Python versions\n    name: Test package\n    runs-on: ${{ matrix.os }}\n    strategy:\n      fail-fast: false\n      matrix:\n        python-version:\n        - 3.9\n        - 3.10\n        - 3.11\n        - 3.12\n        - 3.13\n        os:\n        - ubuntu-latest\n        - macos-latest\n        - windows-latest\n</code></pre>"},{"location":"steps/ci/#test-steps","title":"Test steps","text":"<p>The only thing you need to set up now is the same process you would run locally. Check out the code, set up the environment, install your package and run the tests. The process might look like this:</p> <pre><code># ...\n  test:\n    steps:\n    - name: Checkout code\n      uses: actions/checkout@v4\n    - name: Set up Python\n      uses: actions/setup-python@v4\n      with:\n        python-version: ${{ matrix.python-version }}\n    - name: Install package and dependencies\n      run: |\n        pip install -e .\n    - name: Run tests\n      run: |\n        pip install pytest\n        pytest .\n</code></pre>"},{"location":"steps/ci/#linting-and-formatting","title":"Linting and Formatting","text":"<p>There are many different solutions. But if you have a pre-commit set up, as discussed in the formatting section, the easiest way is to simply use pre-commot.ci as an external hook to do the pre-commit. Check the documentation for details. Especially for open source projects, this is very easy. Then run the exact same rules locally and in the CI/CD pipeline. </p> <p>Otherwise, if your project is private or you cannot use pre-commit.ci for some other reason, you would need to create a custom GitHub action that checks out your code and runs the pre-commit. If the pre-commit fails, the job will fail. At best, it would also commit all changes back to the branch (this is what pre-commit.ci does). The first part is fairly easy to set up, the second part can be a bit more complicated because of authentication issues from within your job. But it can be done.</p>"},{"location":"steps/ci/#dependency-updates","title":"Dependency updates","text":"<p>Dependency updates are a great way to keep your code up to date. </p>"},{"location":"steps/ci/#dependabot","title":"Dependabot","text":"<p>Dependabot is a GitHub tool that automatically creates pull requests to update your GitHub Actions dependencies. It is very easy to setup.</p>"},{"location":"steps/ci/#pre-commitci","title":"pre-commit.ci","text":"<p>pre-commit.ci can be used not only to perform the pre-commit on your project, but also to create pull requests to update your pre-commit dependencies. It can be set up in the same way as the pre-commit hook.</p>"},{"location":"steps/ci/#renovate","title":"Renovate","text":"<p>Renovate is another more feature-rich tool for updating your dependencies. It is not necessary for a classic Python package, but it is worth mentioning. You can either host it yourself or rely on their cloud service.</p>"},{"location":"steps/ci/#code-analysis","title":"Code analysis","text":"<p>Code analysis tools can check your code for security vulnerabilities and other problems.</p>"},{"location":"steps/ci/#codeql","title":"CodeQL","text":"<p>[CodeQL (https://codeql.github.com/) is GitHub's code analysis tool. If you already host your project on GitHub, you can add it to your project with a single click. It will then run on every commit and pull request. It is also free for public repositories. See the documentation to learn how to set up CodeQL for your project.</p>"},{"location":"steps/ci/#resources","title":"Resources","text":"<ul> <li>GitHub Actions Documentation</li> <li>GitLab CI/CD Documentation</li> <li>CircleCI Documentation</li> <li>Jenkins Documentation</li> <li>Codecov Documentation (for code coverage reporting)</li> <li>SonarQube Documentation (for code quality analysis)</li> <li>GitHub Actions Marketplace</li> <li>Dependabot Documentation</li> </ul>"},{"location":"steps/document/","title":"6. Document","text":"<p>Without documentation, no one will know what your project does, how it works, and how to use it. Even without a large user base, having good documentation is an advantage. Your future self will thank you for it. Documentation is not only important for users, but also for developers.</p> <p>Example</p> <p>See demo project:</p> <p> Before |  After |  Diff</p>"},{"location":"steps/document/#types-of-documentation","title":"Types of Documentation","text":"<p>To provide documentation, there are generally two types of documentation: </p> <ul> <li>Inline documentation: Comments, docstrings and also type hints in your code. This helps developers and yourself to understand the code, and can be used to generate documentation automatically.</li> <li>Dedicated documentation site: A separate documentation site that provides a more detailed overview of your software and how to use it.</li> </ul>"},{"location":"steps/document/#inline-documentation","title":"Inline Documentation","text":"<p>There is really no reason not to have good inline documentation with comments, docstrings and type hints. As discussed in the type section, type hints are self-documenting. Even if no one else ever uses or develops your project, good inline documentation will help keep your code readable and maintainable for your future self.</p>"},{"location":"steps/document/#docstrings","title":"Docstrings","text":"<p>PEP 257 - Docstring Conventions defines the conventions for docstrings. Docstrings are used to document modules, classes, methods and functions. They can also be used to generate API reference documentation, which makes them very powerful. There are several styles, all of which follow the defined convention. Which one you choose is a matter of taste. But if you choose one, tools like ruff can lint your docstrings, and static site generators (see below) can generate a nice API reference without any further effort. This way, you get good inline documentation and a dedicated docs page at the same time.</p>"},{"location":"steps/document/#numpy-style","title":"numpy-style","text":"<p>numpydoc is a docstring format used by the NumPy and SciPy projects, and is very popular in the scientific Python community. It is also the default format for many tools such as Sphinx and MkDocs.</p> <pre><code>def add(a: float, b: float) -&gt; float:\n    \"\"\"\n    Add two numbers.\n\n    Longer description of the function.\n\n    Parameters\n    ----------\n    a : float\n        The first number.\n    b : float\n        The second number.\n    Returns\n    -------\n    float\n        The sum of the two numbers.\n    \"\"\"\n    return a + b\n</code></pre> <p>There are many more sections in numpydoc format. If you want to use the mentioned doctests, you can use the <code>Examples</code> section:</p> <pre><code>def add(a: float, b: float) -&gt; float:\n    \"\"\"\n    ...\n\n    Examples\n    --------\n    &gt;&gt;&gt; add(1, 2)\n    3.0\n    &gt;&gt;&gt; add(1.5, 2.5)\n    4.0\n    \"\"\"\n</code></pre> <p>Check the numpydoc style guide for more information.</p>"},{"location":"steps/document/#google-style","title":"Google-style","text":"<p>Another popular docstring format is the Google style. It is used by the Google Python Style Guide, also used by many other projects and also supported by Sphinx and MkDocs.</p> <pre><code>def add(a: float, b: float) -&gt; float:\n    \"\"\"\n    Add two numbers.\n\n    Longer description of the function.\n\n    Args:\n        a (float): The first number.\n        b (float): The second number.\n\n    Returns:\n        float: The sum of the two numbers.\n\n    Examples:\n        &gt;&gt;&gt; add(1, 2)\n        3.0\n        &gt;&gt;&gt; add(1.5, 2.5)\n        4.0\n    \"\"\"\n    return a + b\n</code></pre>"},{"location":"steps/document/#sphinx-style","title":"Sphinx-style","text":"<p>Sphinx also provides its own docstring format. It is not as popular as the other two formats and is not used by many projects. You need another extension installed, if you wanna use Sphinx with other formats, but besides that, there are no real advantages to use it.</p> <pre><code>def add(a: float, b: float) -&gt; float:\n    \"\"\"\n    Add two numbers.\n\n    Longer description of the function.\n\n    :param a: The first number.\n    :type a: float\n    :param b: The second number.\n    :type b: float\n    :return: The sum of the two numbers.\n    :rtype: float\n\n    .. doctest::\n\n        &gt;&gt;&gt; add(1, 2)\n        3.0\n        &gt;&gt;&gt; add(1.5, 2.5)\n        4.0\n    \"\"\"\n    return a + b\n</code></pre>"},{"location":"steps/document/#dedicated-documentation","title":"Dedicated Documentation","text":"<p>Docstrings can be used to automatically generate an API reference. But for a complete documentation site, you need more than just the API reference. You can add a landing page, a getting started guide, tutorials, examples and more. The structure of always linking a user guide to an API reference and back is a good practice. This way a user can easily find information about the function signature, but also get an explanation of how to use it. See the pydantic documentation for a good example of this structure.</p> <p>Your additional documentation will live in <code>docs/</code> (or similar, but in its own directory): <pre><code>python-package-demo/\n\u251c\u2500\u2500 docs/\n\u2502   \u251c\u2500\u2500 index.rst\n\u2502   \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 test/\n\u2502   \u251c\u2500\u2500 conftest.py  # when using pytest\n\u2502   \u2514\u2500\u2500 test_example.py\n\u251c\u2500\u2500 src/\n\u2502   \u2514\u2500\u2500 python_package_demo/\n\u2502       \u251c\u2500\u2500 __init__.py\n\u2502       \u2514\u2500\u2500 example.py\n\u251c\u2500\u2500 LICENSE\n\u251c\u2500\u2500 pyproject.toml\n\u251c\u2500\u2500 README.md\n\u2514\u2500\u2500 ...\n</code></pre></p>"},{"location":"steps/document/#readme","title":"Readme","text":"<p>This starts with the README.md, which is usually the first thing your users will see. The documentation landing page is usually very similar to the README.md, or you can provide a custom landing page. Although there are no hard and fast rules about how a README.md should be structured, it is a good idea to stick to the standard. Tools like makeareadme.com can help you create a good README.md with a good structure. Or check out this guide or just browse through some awesome readme's for inspiration.</p>"},{"location":"steps/document/#developer-documentation","title":"Developer documentation","text":"<p>A dedicated developer page is also a good idea. It should contain information on how to contribute to the project, how to set up the development environment, how to run tests, and how to build the project. This is particularly important for open source projects.</p>"},{"location":"steps/document/#tools","title":"Tools","text":"<p>To create a dedicated website for your documentation, you need a static website generator and somewhere to host it.</p>"},{"location":"steps/document/#static-site-generators","title":"Static Site Generators","text":"<p>A static site generator is a tool that takes your documentation files and generates HTML files from them. There are different tools for this, and they all allow you to use different themes and plugins.</p>"},{"location":"steps/document/#sphinx","title":"Sphinx","text":"<p>Sphinx is a static page generator based on the reStructured markup language. It also supports other formats (such as Markdown), but is designed for reStructured text. Sphinx is very powerful and flexible, and is probably the most popular tool used. As it has been around for a long time, there are a lot of plugins and themes available.</p>"},{"location":"steps/document/#rst-vs-md","title":"<code>.rst</code> vs <code>.md</code>","text":"<p>On the other hand, reStructured text is less intuitive to use and has a higher learning curve with a more challenging syntax than simple markdown. If you want to encourage community contributions to your documentation, markdown is the better choice, as it's easier to read and write. .rst` simply offers more features, but this is less of a problem with other more modern static site generators. Using Markdown also has the advantage that other viewers (such as your IDE or git hosting platform) are more likely to render it correctly.</p> <p><code>.rst</code> syntax: <pre><code>Title\n=====\n\nA simple example with a `link &lt;https://www.google.com&gt;`_.\n\n.. warning::\n\n    This is a warning.\n\n.. code-block:: python\n\n    def add(a: float, b: float) -&gt; float:\n        \"\"\"\n        Add two numbers.\n\n        Longer description of the function.\n\n        :param a: The first number.\n        :type a: float\n        :param b: The second number.\n        :type b: float\n        :return: The sum of the two numbers.\n        :rtype: float\n        \"\"\"\n        return a + b\n</code></pre></p> <p><code>.md</code> syntax: <pre><code># Title\n\nA simple example with a [link](https://www.google.com).\n\n!!! warning\n\n    This is a warning.\n\n```python\ndef add(a: float, b: float) -&gt; float:\n    \"\"\"\n    Add two numbers.\n\n    Longer description of the function.\n\n    :param a: The first number.\n    :type a: float\n    :param b: The second number.\n    :type b: float\n    :return: The sum of the two numbers.\n    :rtype: float\n    \"\"\"\n    return a + b\n</code></pre></p>"},{"location":"steps/document/#mkdocs","title":"MkDocs","text":"<p>mkdocs is a static site generator based on Markdown and only supports Markdown. It is very easy to use and has a lot of themes and plugins available. The documentation you are reading is built with the Material Theme MkDocs[]. It also provides plugins and most of the features missing from the standard markdown syntax. If you are not sure which one to use, mkdocs is a good choice.</p>"},{"location":"steps/document/#gitbook","title":"GitBook","text":"<p>GitBook is another page generator based on Markdown that produces nice looking docs. The main pro and con is that it is proprietary and not open source. Which has the advantage that they also provide a hosting solution.</p>"},{"location":"steps/document/#hosting","title":"Hosting","text":"<p>The final step is to host your documentation somewhere so that it is accessible to the public.</p>"},{"location":"steps/document/#readthedocs","title":"readthedocs","text":"<p>The most popular tool used by many small to medium sized projects is readthedocs. It is free for open source projects and has many features. It can automatically build your documentation and host it for you. It also has many integrations with other tools such as GitHub, GitLab, Bitbucket and many more. It is very easy to set up and you do not need to provide your own CI/CD pipeline. You simply connect your account, which adds a web hook to your repository. It is so popular that the generated url of \"https://.readthedocs.io/\" is used as standard for many projects. Sphinx and MkDocs are both supported, and there are only a few configurations that you can set up in the <code>readthedocs.yml</code> file."},{"location":"steps/document/#github-pages","title":"GitHub Pages","text":"<p>GitHub Pages is another free hosting solution for open source projects. Since many projects are already hosted on GitHub, integration with the GitHub ecosystem is very easy. You can use it with Sphinx, MkDocs or just plain Markdown and choose a theme via GitHub Pages.</p>"},{"location":"steps/document/#other-resources","title":"Other Resources","text":"<ul> <li>Markdown Guide</li> <li>Documenting Python Code: A Complete Guide \u2013 Real Python</li> <li>Python docstring formats (styles) and examples | note.nkmk.me</li> <li>Writing Comments in Python (Guide) \u2013 Real Python</li> <li>Keep a Changelog</li> <li>Sphinx Documentation</li> <li>MkDocs Documentation</li> <li>Material for MkDocs</li> <li>Read the Docs Documentation</li> <li>Awesome Documentation Tools</li> <li>Python Documentation Best Practices</li> </ul>"},{"location":"steps/format/","title":"4. Format &amp; Lint","text":"<p>A code formatter is a tool that automatically formats your code according to a set of rules. This helps to keep your code clean and consistent, which makes it easier to read and maintain, and simply more aesthetically pleasing. You do not have to format your code manually, and collaboration with other developers is easier because personal style is removed.</p> <p>A code linter is a tool that checks your code for style violations and errors. It helps you find bugs and potential problems in your code. A linter can also be used to enforce coding standards and best practices.</p> <p>The difference between a formatter and a linter is that a formatter automatically formats your code, while a linter checks your code for style violations and errors. Although some linters can fix some of the problems they find, they are not intended to be used as formatters. A linter is more like a code review tool that helps you find potential problems in your code.</p> <p>PEP 8 - Style Guide for Python Code is the official style guide for Python code. It is a good idea to follow this style guide as it is widely accepted and used by many projects. The tools mentioned here mostly follow this style guide or define additional rules.</p> <p>Example</p> <p>See demo project:</p> <p> Before |  After |  Diff</p>"},{"location":"steps/format/#tools","title":"Tools","text":"<p>There are several tools available for formatting your code. You can only use one of them, as a combination may cause conflicts. Linters can be used in combination with formatters and can check for a specific linting task or apply PEP 8 rules in a broader sense. See this awesome list for more tools.</p>"},{"location":"steps/format/#black","title":"<code>black</code>","text":"<p>Black is a code formatter that formats your code according to the PEP 8 style guide. It is opinionated and has a set of rules that it follows.</p>"},{"location":"steps/format/#isort","title":"<code>isort</code>","text":"<p>isort is a code formatter that formats your imports. It sorts your imports according to the PEP 8 style guide and removes unused imports.</p>"},{"location":"steps/format/#flake8","title":"<code>flake8</code>","text":"<p>flake8 is a code linter that checks your code for style violations and errors. It is a combination of <code>pyflakes</code>, <code>pycodestyle</code> and <code>mccabe</code>. It is widely used and has a lot of plugins that can be used to extend its functionality.</p>"},{"location":"steps/format/#pep8-naming","title":"<code>pep8-naming</code>","text":"<p>pep8-naming is a plugin for <code>flake8</code> that checks your code for naming conventions. It checks for PEP 8 naming conventions and can be used to enforce naming conventions in your code.</p>"},{"location":"steps/format/#pyflake","title":"<code>pyflake</code>","text":"<p>pyflakes is a code linter that checks your code for style violations and errors. It is a lightweight linter that checks your code for common mistakes and potential problems.</p>"},{"location":"steps/format/#ruff","title":"<code>ruff</code>","text":"<p>There are many other linters and formatters out there, but most of them can be replaced by Ruff. It is a fairly new code formatter and linter at the same time. It has recently gained a lot of popularity and is being adapted by many projects. The Ruff formatter can be a drop-in replacement for <code>black</code>. It is also much faster than other tools. The Ruff linter supports over 800 linting rules and can replace all the above tools. A complete list of supported rules can be found here. It is recommended that you adopt the Ruff formatter first and then start applying the standard linter rules. You can extend from there if you like, but they already cover the most important things.</p>"},{"location":"steps/format/#basic-usage","title":"Basic usage","text":"<p>To run the formatter just run the following command:</p> <p><pre><code>ruff format # apply the formatter to all files\nruff format my_file.py # apply the formatter to a single file\n</code></pre> And to run the linter:</p> <p><pre><code>ruff check # check all files\nruff check --fix # check and fix all rules which can be fixed automatically\n</code></pre> Some rules cannot be fixed automatically, so you need to fix them manually. What the problem is and why this might be bad practice is always explained in the rule documentation.</p> <p>Warning</p> <p><code>ruff format</code> and <code>ruff check --fix</code> will modify your files (potentially quite a lot). So make sure to run it on a clean git branch and commit your changes before running it. You can also use <code>ruff check</code> to check your files without modifying them.</p>"},{"location":"steps/format/#configuration","title":"Configuration","text":"<p>The default rules only cover the most common errors. But you can check many more things by simply adding a configuration file. The two most common ways are to add rules to the <code>pyproject.toml' file (which you created in the [build step](build.md)) or to create a</code>ruff.toml` file for your project. The configuration documentation can be found here.</p> <p>With additional rules you can check many things. For example, use <code>mcabbe</code> (rule <code>C90</code>) to check the cyclomatic complexity of your code. This is a good indicator of the readability of your code. You can also use <code>pydocstyle</code> (rule <code>D</code>) to check the docstrings of your code. This is a good indicator of the readability of your code, and helps to keep your code clean and maintainable. You can use <code>Rule NPY</code> to update your code to Numpy version 2.0.0. Or use <code>pandas-vet</code> (rule <code>PD</code>) to check your code for common errors when using pandas.</p>"},{"location":"steps/format/#pre-commit","title":"pre-commit","text":"<p>Running formatters and linters can be set up in the CI/CD pipeline, and most IDEs have plugins for them too. But to allow developers to run the exact tools that are set up in the project, you can also use git hooks. This is a great way to ensure that your code is always formatted and lined up before you commit it.</p> <p>Git hooks are a feature of git, and you can set them to run any command before certain triggers. This can be a bit tedious, and you need all the tools installed on your machine. But there are tools like pre-commit that make it easy to set up git hooks. It is a framework for managing and maintaining multilingual pre-commit hooks. It is a great way to ensure that your code is always formatted and linked before you commit.</p> <p>All you need to do is create a <code>.pre-commit-config.yaml</code> file in your project. Here is a simple example:</p> <pre><code># .pre-commit-config.yaml\nrepos:\n# Run ruff to lint and format\n- repo: https://github.com/astral-sh/ruff-pre-commit\n  # Ruff version.\n  rev: v0.9.9\n  hooks:\n    # Run the linter.\n  - id: ruff\n    args: [--fix]\n    # Run the formatter.\n  - id: ruff-format\n</code></pre> <p>Now anyone can clone your project and run <code>pre-commit install</code> to install the git hook. pre-commit will automatically run the Ruff linter and formatter before each commit. It will also manage any dependencies, so you do not need to have ruff installed on your machine. You can also run <code>pre-commit run --all-files</code> to run the linter and formatter on all files in your project. </p> <p>There are many other hooks available. The ci section also shows how to run pre-commit in the CI/CD pipeline.</p>"},{"location":"steps/format/#resources","title":"Resources","text":"<ul> <li>How to Write Beautiful Python Code With PEP 8 \u2013 Real Python</li> <li>life4/awesome-python-code-formatters: A curated list of awesome Python code formatters</li> <li>Python code formatters \u2022 DeepSource</li> <li>Ruff Documentation</li> <li>Comparing Python Linting Tools</li> </ul>"},{"location":"steps/maintain/","title":"10. Maintain","text":"<p>Finally, you need to keep your project alive. Maintaining an open source project is just as important as creating it. A well-maintained project attracts more users and contributors, while an abandoned project can quickly become obsolete or insecure. The Open Source Guides has many great resources on how to maintain your project (e.g. What does it mean to be a maintainer?).</p>"},{"location":"steps/maintain/#resources","title":"Resources","text":"<p>General</p> <ul> <li>Open Source Guides | Learn how to launch and grow your project.</li> <li>SustainOSS | A Space for Open Source Sustainers</li> <li>What is Open Source? | opensource.dev</li> <li>Producing Open Source Software</li> </ul> <p>Community</p> <ul> <li>Contributor Covenant: A Code of Conduct for Open Source and Other Digital Commons Communities</li> </ul> <p>Maintenance</p> <ul> <li>Planning and tracking with Projects - GitHub Docs</li> <li>Git - Maintaining a Project</li> <li>Home | endoflife.date</li> </ul> <p>Metrics</p> <ul> <li>Home - CHAOSS</li> <li>GitHub Insights</li> </ul> <p>Funding</p> <ul> <li>GitHub Sponsors</li> <li>Buy Me a Coffee</li> <li>Open Collective</li> <li>Tidelift</li> <li>NumFOCUS</li> </ul>"},{"location":"steps/publish/","title":"8. Publish","text":"<p>We are ready to publish your package. Users don't want to install your package through a git hosting platform, but through a dedicated package manager. In the Python ecosystem, there are two main platforms for making your package available.</p>"},{"location":"steps/publish/#pypi","title":"PyPI","text":"<p>PyPI is the Python Package Index. It is a central repository for Python packages and is used by pip to install packages. PyPI is a good place to publish your package as it is the most widely used package manager for Python. There are several ways to publish your package to PyPI. A simple CI/CD integration is discussed in the CI/CD section. PyPI also has a test instance which you can use to test your workflow. You could also use it to publish each commit to a test instance and then use the main instance for releases. But this is probably overkill for most projects.</p>"},{"location":"steps/publish/#twine","title":"twine","text":"<p>If you'd like to play around with this process locally, you can use the twine command line tool. Twine is a command line tool for uploading packages directly to PyPI. It is very simple:</p> <p>Using twine:</p> <ol> <li>Create some distributions in the normal way:     <pre><code>python -m build\n</code></pre></li> <li>Upload to Test PyPI and verify things look right:     <pre><code>twine upload --repository testpypi dist/*\n</code></pre></li> <li>Verify the upload:     <pre><code>pip install --index-url https://test.pypi.org/simple/ &lt;your-package&gt;\n</code></pre> Or to upload to the main PyPI: <pre><code>twine upload dist/*\n</code></pre></li> </ol> <p>Note</p> <p>This process expects that you have the package setup correctly, as discussed in the build section.</p>"},{"location":"steps/publish/#conda","title":"Conda","text":"<p>Conda is a package manager for Python and other languages. It is used to manage packages and environments and has the advantage of being able to handle non-Python packages. While you can install a pip package in a conda environment, it is recommended to use conda packages for conda environments. Conda-forge is a community-driven collection of conda packages. It is the usual place to publish your package. You could of course use a different channel. You will need to set up a conda feed for your package once. See the conda-forge documentation for more information. The process is a bit more complicated than PyPI. But then condaforge can be triggered by any new PyPI release, so you only need to trigger it once.</p>"},{"location":"steps/publish/#package-manager","title":"Package manager","text":"<p>While <code>pip</code> is the most common package manager for PyPI, there are others worth mentioning:</p> <ul> <li>pip</li> <li>Poetry </li> <li>uv</li> <li>pipx</li> </ul> <p>Also for conda there are other package managers:</p> <ul> <li>conda</li> <li>mamba</li> </ul> <p>Here are additional resources you could add to the \"Resources\" section of your guide:</p>"},{"location":"steps/publish/#resources","title":"Resources","text":"<ul> <li>PyPI Documentation</li> <li>Conda-forge Documentation</li> <li>Twine Documentation</li> <li>Packaging and Distributing Projects</li> <li>Build Documentation</li> <li>TestPyPI</li> <li>Conda Package Maintenance</li> </ul>"},{"location":"steps/release/","title":"7. Release","text":"<p>Now that you have a well-tested, formatted and documented project, it is time to think about a release strategy.</p>"},{"location":"steps/release/#versioning","title":"Versioning","text":"<p>Versioning is a way of keeping track of changes in your project. It is important to have a clear versioning strategy to communicate changes to your users. There are several different versioning strategies, but the most common are semantic versioning and calendar versioning.</p>"},{"location":"steps/release/#semantic-version","title":"Semantic Version","text":"<p>Semantic Versioning is a versioning strategy that uses a three-part version number: MAJOR.MINOR.PATCH. Projects such as Python itself, pandas, numpy and many others use this versioning scheme.</p> <ul> <li>MAJOR version is incremented when you make incompatible API changes</li> <li>MINOR version is incremented when you add functionality in a backwards-compatible manner</li> <li>PATCH version is incremented when you make backwards-compatible bug fixes</li> </ul> <p>By following this versioning strategy, you can easily communicate to your users what has changed in your project. It is also recommended that you actually use the scheme. Many projects have the x.x.x versioning scheme, but don't follow the rules. For example, they simply increment the patch version for every release, even if it is a new feature. This is not good practice and can lead to confusion. A patch should never be a new feature.</p> <p>The disadvantage of this approach is that you have to distinguish between a feature and a bug fix. This is not always easy, especially in larger projects. What if you want to release a new patch, but the patch sits on top of another feature commit that you don't want to release yet? You could do this by creating a release branch, and cherry-picking the patch on that branch to create another release from there. But this is not always easy, and can lead to confusion. Larger projects use different branches for different releases. For smaller projects, this might be too much extra work.</p>"},{"location":"steps/release/#calendar-versioning","title":"Calendar Versioning","text":"<p>If it is difficult to actually follow the rules of semantic versioning, you might want to look at calendar versioning. The advantage of this approach is that the user also gets a sense of how old and maintained the project is. See this guide for more information on when to use which scheme. But whichever scheme you choose, it is important to be consistent and follow the rules.</p>"},{"location":"steps/release/#resources","title":"Resources","text":"<ul> <li>Versioning - Python Packaging User Guide</li> <li>Python Package Release Checklist</li> <li>GitHub Release Documentation</li> <li>PyPI Publishing Documentation</li> <li>Conventional Commits Specification</li> <li>Keep a Changelog</li> <li>Twine Documentation (for publishing packages)</li> <li>setuptools_scm (for managing versions from git tags)</li> </ul>"},{"location":"steps/test/","title":"3. Test","text":"<p>\u201cNever allow the same bug to bite you twice.\u201d - Steve Maguire</p> <p>Testing is an important part of software development, and it can be a big deal. But it doesn't have to be. You want to make sure that your code works as expected and that you don't introduce bugs into your production code. There are many different testing strategies and tools available. This section will give you a brief overview of the most common ones and how to use them.</p> <p>Example</p> <p>See demo project:</p> <p> Before |  After |  Diff</p>"},{"location":"steps/test/#testing-strategies","title":"Testing strategies","text":"<p>There are many different testing strategies. And different projects will require different strategies. But the most common ones you will probably want to use are unit tests and integration tests.</p> <p>Tests live in <code>test/</code>: <pre><code>python-package-demo/\n\u251c\u2500\u2500 test/\n\u2502   \u251c\u2500\u2500 conftest.py  # when using pytest\n\u2502   \u2514\u2500\u2500 test_example.py\n\u251c\u2500\u2500 src/\n\u2502   \u2514\u2500\u2500 python_package_demo/\n\u2502       \u251c\u2500\u2500 __init__.py\n\u2502       \u2514\u2500\u2500 example.py\n\u251c\u2500\u2500 LICENSE\n\u251c\u2500\u2500 pyproject.toml\n\u251c\u2500\u2500 README.md\n\u2514\u2500\u2500 ...\n</code></pre></p>"},{"location":"steps/test/#unit-tests","title":"Unit tests","text":"<p>Unit tests are the most common type of tests. They test a single unit of code in isolation. This means that you test a single function or class and make sure that it works as expected. Unit tests are usually quick and easy to write. In most projects, they will make up the majority of your tests.</p> <p>Let's say we wanna test a simple unit of code: <pre><code># src/python_package_demo/example.py\ndef add(a: float, b: float) -&gt; float:\n    return a + b\n</code></pre> We can write a unit test for this function <pre><code># test/test_example.py\nimport pytest\nfrom python_package_demo.example import add\ndef test_add():\n    assert add(1, 2) == 3\n    assert add(1.5, 2.5) == 4.0\n    assert add(-1, 1) == 0\n</code></pre> and run it with <code>pytest</code>: <pre><code>$ pytest\n=========================== test session starts ============================\nplatform linux -- Python 3.x.y, pytest-8.x.y, pluggy-1.x.y\nrootdir: /home/sweet/project\ncollected 1 item\ntest/test_example.py .                                             [100%]\n============================ 1 passed in 0.12s =============================\n</code></pre></p>"},{"location":"steps/test/#integration-tests","title":"Integration tests","text":"<p>Integration testing tests the interaction between different units of code. This means that you test how different functions or classes work together. Integration tests tend to be slower and more complex than unit tests. They are used to make sure that the different parts of your code work together as expected.</p> <p>Info</p> <p>In the context of modelling, creating an integration test could be as simple as testing your model framework by running a test configuration of your model.</p>"},{"location":"steps/test/#static-code-anaylsis","title":"Static code anaylsis","text":"<p>Static code analysis tools check code for known \"smells\" and problems using a database of previously identified problematic code patterns. Tools often provide a suggestion on how to improve the code. Compared to unit tests, static code analysis can be a bit slower, but can also provide insights to the coders and help them improve. There are several static code analysis frameworks available, e.g. prospector</p> <p>To run a static code analysis install prospector <pre><code>pip install prospector\n</code></pre></p> <p>and then run it from the project's base folder <pre><code>prospector\n</code></pre></p> <p>Static code analysis are also easily included in pre-commit setups.</p> <p>To run prospector before pushing use <pre><code>repos:\n  - repo: local\n    hooks:\n      - id: prospector\n        name: prospector\n        entry: prospector\n        stages: [ push ]\n        language: python\n        python: \"3.9\"\n        pass_filenames: false\n        always_run: true\n        additional_dependencies:\n          - prospector\n</code></pre></p>"},{"location":"steps/test/#other-tests","title":"Other tests","text":"<p>There are many other types of tests, but you will probably be good at unit and integration testing. </p>"},{"location":"steps/test/#test-driven-development","title":"Test driven development","text":"<p>In addition, there is the concept of Test Driven Development (TDD). Here you write your tests before you write your code. This means that you first write a test that fails, and then write the minimum amount of code to pass that test. The advantages of TDD are instant feedback and potentially better design of your code, as you are forced to think about the interface of your code before you write it and see where it goes. This may be overkill for small projects, but in the end it is a matter of style and worth a try.</p>"},{"location":"steps/test/#tools","title":"Tools","text":"<p>There are many different tools in Python that make it easy to test your code.</p>"},{"location":"steps/test/#pytest","title":"<code>pytest</code>","text":"<p><code>pytest</code> is a testing framework that makes it easy to write simple and scalable test cases. It is the most common testing framework in Python and is used by many projects. It has a lot of features and plugins that make it easy to use.</p> <p>A quick example: <pre><code># content of test_sample.py\ndef inc(x):\n    return x + 1\n\n\ndef test_answer():\n    assert inc(3) == 5\n</code></pre> To execute it: <pre><code>$ pytest\n=========================== test session starts ============================\nplatform linux -- Python 3.x.y, pytest-8.x.y, pluggy-1.x.y\nrootdir: /home/sweet/project\ncollected 1 item\n\ntest_sample.py F                                                     [100%]\n\n================================= FAILURES =================================\n_______________________________ test_answer ________________________________\n\n    def test_answer():\n&gt;       assert inc(3) == 5\nE       assert 4 == 5\nE        +  where 4 = inc(3)\n\ntest_sample.py:6: AssertionError\n========================= short test summary info ==========================\nFAILED test_sample.py::test_answer - assert 4 == 5\n============================ 1 failed in 0.12s =============================\n</code></pre></p> <p>Check the pytest documentation for more informations.</p>"},{"location":"steps/test/#unittest","title":"<code>unittest</code>","text":"<p><code>unittest</code> is the built-in testing framework in Python. It is a bit more complex than <code>pytest</code>, but it is also very powerful. It is used by many projects and is a good choice if you want to use the built-in tools.</p> <p>A Basic example: <pre><code>import unittest\n\nclass TestStringMethods(unittest.TestCase):\n\n    def test_upper(self):\n        self.assertEqual('foo'.upper(), 'FOO')\n\n    def test_isupper(self):\n        self.assertTrue('FOO'.isupper())\n        self.assertFalse('Foo'.isupper())\n\n    def test_split(self):\n        s = 'hello world'\n        self.assertEqual(s.split(), ['hello', 'world'])\n        # check that s.split fails when the separator is not a string\n        with self.assertRaises(TypeError):\n            s.split(2)\n\nif __name__ == '__main__':\n    unittest.main()\n</code></pre></p> <p>Check the unittest documentation for more informations.</p>"},{"location":"steps/test/#coverage","title":"<code>coverage</code>","text":"<p>When you add tests to your project, it is hard to know if you are testing everything, or which parts are missing.</p> <p><code>coverage</code> is a tool for measuring code coverage in Python programs. It monitors which parts of your code are executed by <code>pytest</code> or <code>unittest</code> and generates a report showing which parts of your code are not covered by tests. This can help you identify areas of your code that need more testing.</p> <p>An example report looks like this: <pre><code>$ coverage report -m\nName                      Stmts   Miss  Cover   Missing\n-------------------------------------------------------\nmy_program.py                20      4    80%   33-35, 39\nmy_other_module.py           56      6    89%   17-23\n-------------------------------------------------------\nTOTAL                        76     10    87%\n</code></pre></p> <p>Check the coverage documentation for more informations.</p>"},{"location":"steps/test/#codecov","title":"Codecov","text":"<p>There are services like Codecov or Coveralls that can help you visualise your coverage reports. They provide a web interface to see which parts of your code are covered by tests and which are not. This can also be integrated into your CI/CD pipeline to automatically generate coverage reports for each commit or pull request. CI/CD is discussed in the CI section.</p>"},{"location":"steps/test/#doctest","title":"<code>doctest</code>","text":"<p><code>doctest</code> is a module that allows you to test your code by running examples embedded in the documentation. This means you can kill two birds with one stone: you can write documentation and tests at the same time.</p> <p>A simple example: <code>example.txt</code>: <pre><code>The ``example`` module\n======================\n\nUsing ``factorial``\n-------------------\n\nThis is an example text file in reStructuredText format.  First import\n``factorial`` from the ``example`` module:\n\n    &gt;&gt;&gt; from example import factorial\n\nNow use it:\n\n    &gt;&gt;&gt; factorial(6)\n    120\n</code></pre> Doctest will search for the <code>&gt;&gt;&gt;</code> prompt in any text files (also docstrings) and execute the code. <pre><code>$ python -m doctest example.txt\nFile \"./example.txt\", line 14, in example.txt\nFailed example:\n    factorial(6)\nExpected:\n    120\nGot:\n    720\n</code></pre> So you know your documentation is up to date, you provide valuable examples, and you can test your code without writing tests.</p> <p>Check the doctest documentation for more informations.</p>"},{"location":"steps/test/#hypothesis","title":"<code>hypothesis</code>","text":"<p><code>hypothesis</code> is another, more flexible way of writing unit tests. Instead of providing actual test data, you provide data specifications, and <code>hypothesis</code> will test those specifications. This is a way of catching edge cases that a normal unit test might not catch, but would still be covered by a unit test.</p> <p>An example: Let's say you have to functions <code>encode</code> and <code>decode</code> that encode and decode a string. With <code>hypothesis</code> you can test that via: <pre><code>from hypothesis import given\nfrom hypothesis.strategies import text\n\n\n@given(text())\ndef test_decode_inverts_encode(s):\n    assert decode(encode(s)) == s\n</code></pre></p> <p>Check the hypothesis documentation for more informations.</p>"},{"location":"steps/test/#resources","title":"Resources","text":"<ul> <li>Getting Started With Testing in Python \u2013 Real Python</li> <li>Testing Your Code \u2014 The Hitchhiker's Guide to Python</li> <li>The different types of testing in software | Atlassian</li> <li>Python's doctest: Document and Test Your Code at Once \u2013 Real Python</li> <li>Property-Based Testing With Python</li> <li>Hypothesis for Property-Based Testing</li> <li>Pytest Documentation</li> <li>Coverage.py Documentation</li> <li>Python unittest Documentation</li> <li>pytest-cov: Coverage plugin for pytest</li> </ul>"},{"location":"steps/type/","title":"5. Type","text":"<p>Python is a dynamically typed language. This means that you don't have to specify the type of a variable when you declare it. While this is one of the advantages of Python - you can write code faster, easier and more flexibly - it can also lead to problems. Because you don't know what type a variable is at runtime, you can run into problems if you try to use a variable in a way that is incompatible with its type. This can lead to bugs that are difficult to find and fix.</p> <p>PEP 484 \u2013 Type Hints introduced type hints to Python, which have been accepted with Python 3.5.</p> <p>Normal Python code: <pre><code>def greeting(name):\n    return 'Hello ' + name\n</code></pre></p> <p>Staticly typed Python code: <pre><code>def greeting(name: str) -&gt; str:\n    return 'Hello ' + name\n</code></pre></p> <p>Python's type hints have no direct effect on the runtime performance of your code. They are designed to be completely optional and ignored during execution. So even if they are typed, you could pass a different type to the function. However, similar to formatters and linters, there are static type checkers that will check this for you. It is recommended to use type hints, as they help you to write correct and self-documenting code. An existing code base can also be typed step by step.</p> <p>Example</p> <p>See demo project:</p> <p> Before |  After |  Diff</p>"},{"location":"steps/type/#tools","title":"Tools","text":""},{"location":"steps/type/#static-type-checkers","title":"Static type checkers","text":"<p>There are different type checkers, but they will all align to PEP 484. However, they are all different and vary in speed. If you don't know where to start, have a look at mypy. If you have a really large code base, you might want to check one of the others.</p>"},{"location":"steps/type/#mypy","title":"mypy","text":"<p>mypy is the most popular static type checker for Python. It was the first major type checker for Python and is widely used. Also, the default checks are not too strict, so you can start using it in an existing code base without too much effort.</p> <p>A simple example of what mypy will check: <pre><code># my_file.py\ndef greeting(name: str) -&gt; str:\n    return 'Hello ' + name\n\ngreeting(3)\ngreeting(b'Alice')\ngreeting(\"World!\")\n\ndef bad_greeting(name: str) -&gt; str:\n    return 'Hello ' * name\n</code></pre> To run mypy, you can use the following command: <pre><code>$ mypy my_file.py\nmy_file.py:5: error: Argument 1 to \"greeting\" has incompatible type \"int\"; expected \"str\"  [arg-type]\nmy_file.py:6: error: Argument 1 to \"greeting\" has incompatible type \"bytes\"; expected \"str\"  [arg-type]\nmy_file.py:10: error: Unsupported operand types for * (\"str\" and \"str\")  [operator]\nFound 3 errors in 1 file (checked 1 source file)\n</code></pre></p> <p>Check the mypy documentation for more informations.</p>"},{"location":"steps/type/#pyright","title":"pyright","text":"<p>pyright is a static type checker for Python created by Microsoft. It is written in TypeScript and runs on Node.js. It is designed to be fast and efficient and might run faster on large code bases than mypy. And since it is developed by Microsoft, it has good support for Visual Studio Code.</p> <p>Check the pyright documentation for more informations.</p>"},{"location":"steps/type/#pytype","title":"pytype","text":"<p>pytype is a static type checker for Python created by Google. </p> <p>Check the pytype documentation for more informations.</p>"},{"location":"steps/type/#pyre","title":"pyre","text":"<p>pyre is a static type checker for Python created by Facebook.</p> <p>Check the pyre documentation for more informations</p>"},{"location":"steps/type/#runtime-type-checkers","title":"Runtime type checkers","text":"<p>There are also runtime type checkers that check the types of variables at runtime. These libraries can also do normal data validation. This is a more advanced topic and does not just sit on top of PEP 484. But for the sake of completeness, there are a few libraries that might be worth looking at.</p>"},{"location":"steps/type/#pydantic","title":"pydantic","text":"<p>pydantic is a data validation and settings management library for Python. It uses Python type hints to validate the data at runtime. It is widely used in the FastAPI framework.</p> <p>Check the pydantic documentation s.</p>"},{"location":"steps/type/#attrs","title":"attrs","text":"<p>attrs is a library for creating classes without writing boilerplate code. It is similar to dataclasses, but has more features and is more flexible. It also uses Python type hints to validate the data at runtime.</p> <p>Check the attrs documentation for more informations.</p>"},{"location":"steps/type/#resources","title":"Resources","text":"<ul> <li>PEP 484 \u2013 Type Hints</li> <li>typing \u2014 Support for type hints \u2014 Python documentation</li> <li>Python Type Checking (Guide) \u2013 Real Python</li> <li>Python Type Checking | TestDriven.io</li> <li>mypy documentation</li> <li>Pydantic: Data Validation and Settings Management</li> </ul>"},{"location":"steps/write/","title":"1. Write","text":"<p>If you are reading this, it can be assumed that you are already familiar with Python. Therefore, this section will not cover the basics, but just point you to some resources.</p> <p>Example</p> <p>See demo project:</p> <p> After</p>"},{"location":"steps/write/#version-control","title":"Version control","text":"<p>If you develop software, you will want to use git. The rest of this guide assumes and requires that you are using git. If not, go and learn git now.</p> <p>If you think you know git, you might want to check out some advanced git tips in this guide. The difference between merging and rebasing is a common source of confusion, git hooks are used later, and git worktrees are a common \"why didn't I know this before\" moment.</p>"},{"location":"steps/write/#ide","title":"IDE","text":"<p>Most of the tools discussed in the following sections can be used via CLI, but also provide IDE plugins. Popular IDEs are VSCode and PyCharm. Both support plugins for linters, formatters, type checkers etc. That is quite useful since you get immediate feedback whith inline errors and warnings.</p>"},{"location":"steps/write/#coding-assistant","title":"Coding Assistant","text":""},{"location":"steps/write/#privacy-compliant-ways","title":"Privacy compliant ways","text":"<p>Of course, LLMs are a great help, but you may have privacy concerns or simply not be allowed to use them. Using models from OpenAI or Anthropic will send your code to their servers.</p> <p>Self-hosting has become very easy. There are many open source models that you can run on your own machine. With Ollama you can run them with a single command, and with Open WebUI you can use them through a great web interface. Continue gives you Copilot-style auto-completion. </p> <p>The main obstacle is hardware. You need a decent GPU to run these models. But this is just a hint that these problems are solvable and you should get on the train.</p>"},{"location":"steps/write/#resources","title":"Resources","text":"<p>Python</p> <ul> <li>BeginnersGuide - Python Wiki</li> <li>Structuring Your Project \u2014 The Hitchhiker's Guide to Python</li> <li>Python Tutorials \u2013 Real Python</li> <li>Python Tutorial</li> <li>Automate the Boring Stuff with Python</li> <li>Python Design Patterns</li> </ul> <p>Git</p> <ul> <li>git - the simple guide - no deep shit!</li> <li>Learn Git - Tutorials, Workflows and Commands | Atlassian</li> <li>Git Tutorial for Beginners: Learn Git in 1 Hour - YouTube</li> <li>Git Cheat Sheet</li> </ul> <p>IDEs &amp; Tools</p> <ul> <li>PyCharm Documentation</li> <li>VS Code Python Tutorial</li> <li>Jupyter Notebook</li> </ul>"}]}